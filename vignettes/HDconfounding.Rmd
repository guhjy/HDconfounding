---
title: "HDconfounding"
author: "Joseph Antonelli"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{HDconfounding}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this vignette we will show you how to use the main functions of the HDconfounding R package. We will simulate data under both a binary and continuous outcome and show how to analyze them using the various functions in the package. For the sake of building the vignette, we will use a relatively small number of covariates throughout (p=20), however, the methods extend to high-dimensional data. We simply restrict to a lower dimensional case here because the code needs to run each time a new user wants to build the vignette, and the functions used are no different for high-dimensional (p > n) data.

### Loading and building the package

To build the package the user must install the devtools R package and then run the following code.


```{r, echo=TRUE, message=FALSE}
#library(devtools)
#install_github(repo = "jantonelli111/HDconfounding")
#library(HDconfounding)
```

If the user wishes to build the vignette (which will take a few more seconds to build), then the following code can be run.


```{r, echo=TRUE, message=FALSE}
#library(devtools)
#install_github(repo = "jantonelli111/HDconfounding", build_vignettes = TRUE)
library(HDconfounding)
```

And to see the vignette the user can type the following into R. Note that the vignette is also available on the github repository github.com/jantonelli111/HDconfounding, which won't require building the vignette.

```{r, echo=TRUE, message=FALSE, eval=FALSE}
#vignette("HDconfounding", package="HDconfounding")
```

### What this package can and can't be used for

The software in this package is intended to estimate causal effects with a large (potentially larger than the sample size) covariate space. The types of data that can be addressed in this package are continuous and binary outcomes, as well as binary or continuous treatments. Our software can estimate causal effects assuming either a homogeneous or heterogeneous treatment effect. It is important to note, however, that the current software only allows for heterogeneous treatment effects when the exposure/treatment is binary. If the treatment is continuous then the homogeneous versions of the codes should be used. For the sake of this vignette, we will mostly restrict to binary treatments, though the use of continuous treatments is exactly the same, except the heterogeneous functions should not be used.

### Continuous outcome, homogeneous treatment effect

First let's generate some data to practice estimating treatment effects with:

```{r}
n = 200
p = 20
x = matrix(rnorm(n*p), n, p)
z = rbinom(n, 1, p=pnorm(0.7*x[,1] + 0.3*x[,2]))
y = rnorm(n, mean=z + 0.3*x[,1] + 0.6*x[,2] + 0.5*x[,3], sd=1)
```

So our sample size is 200, we have 20 covariates, the first 2 covariates are important for confounding adjustment, and the 3rd covariate is a predictor of the outcome. In this case, the treatment effect is homogeneous, i.e does not vary for different values of the covariates. We will now estimate it using both the homogeneous and heterogeneous versions of our approach. Both should yield unbiased answers in this setting, though we expect the heterogeneous approach to be slightly less efficient as it is a more complex model with more parameters.

First, to estimate the homogeneous treatment effect we can run the following

```{r}
sslEB = SSL(y=y, z=z, x=x, nScans=3000, burn=1000, thin=2, lambda0="EB")
```

This model estimates the tuning parameter $\lambda_0$ with empirical Bayes. We recommend this as it is difficult to have prior knowledge about what value this parameter should take. If the user wants to specify their own value of $\lambda_0$, then weight must also be provided (w in the main manuscript) and we recommend a value of 0.01.

```{r, eval=FALSE}
ssl = SSL(y=y, z=z, x=x, nScans=3000, burn=1000, thin=2, lambda0=15, weight = 0.01)
```

The empirical Bayes estimate is calculated using MCMC so the running time is a little longer than pre-selecting $\lambda_0$, which is one reason one might want to choose their own value if they have a large data set. It is important to note though that a poorly chosen value of $\lambda_0$ can lead to poor estimation so we highly recommend the EB option. Let's look at the results on the treatment effect:

```{r}
sslEB$TreatEffect
sslEB$TreatEffectCI
```

There are other things one can pull from the results of this analysis. We can look at the posterior inclusion probabilities of the covariates:

```{r}
sslEB$gammaPostMean
```

And we see that the first three covariates are included in the slab component of the prior as expected. 

### Continuous outcome, heterogeneous treatment effect

Now let's analyze the same data, but allowing for heterogeneous treatment effects. 

```{r}
sslEBhetero = SSLhetero(y=y, z=z, x=x, nScans=3000, burn=1000, thin=2, lambda0="EB")
```

And look at the results:

```{r}
sslEBhetero$TreatEffect
sslEBhetero$TreatEffectCI
```

